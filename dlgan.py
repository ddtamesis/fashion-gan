# -*- coding: utf-8 -*-
"""DLGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TD1GuVb40tEt_EjgU4xBLsPRx5YCo-d8
"""

from skimage.io import imread
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

# mount shared drive to use/access our own photos
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

import zipfile
with zipfile.ZipFile("/content/gdrive/My Drive/DLFinal2/Copy of img.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/gdrive/My Drive/DLFinal2/deepFashion")

file = "/content/gdrive/My Drive/DLFinal2/deepFashion"
# loop through the list of folders
for sub_dir in file:

	# loop through the contents of the
	# list of folders
	for contents in sub_dir:

		# make the path of the content to move
		path_to_content = sub_dir + "/" + contents

		# make the path with the current folder
		dir_to_move = os.path.join(current_folder, path_to_content )

		# move the file
		shutil.move(dir_to_move, merge_folder_path)

def img_to_tensor(img_path):
  img = imread(img_path)
  img = tf.convert_to_tensor(img, dtype=tf.float32)
  # clip data for imshow
  plt.figure()
  plt.imshow(img/255)
  # get img into expected format
  return tf.expand_dims(img, 0)



# Commented out IPython magic to ensure Python compatibility.
try:
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
import numpy as np

tf.keras.backend.set_floatx('float64')

import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec

# %matplotlib inline
plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

# A bunch of utility functions
def show_images(images):
    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)
    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))
    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))

    fig = plt.figure(figsize=(sqrtn, sqrtn))
    gs = gridspec.GridSpec(sqrtn, sqrtn)
    gs.update(wspace=0.05, hspace=0.05)

    for i, img in enumerate(images):
        ax = plt.subplot(gs[i])
        plt.axis('off')
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect('equal')
        plt.imshow(img.reshape([sqrtimg,sqrtimg]))
    return

def preprocess_img(x):
    return 2 * x - 1.0

def deprocess_img(x):
    return (x + 1.0) / 2.0

def rel_error(x, y):
    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))


# Load data from Google Drive
import io
from googleapiclient.http import MediaIoBaseDownload
from google.colab import auth
auth.authenticate_user()
from googleapiclient.discovery import build
drive_service = build('drive', 'v3', cache_discovery=False)

fid = "1r6i_ftDFkjFy6mUq-CNTH1JeN_C0xqDh"


from IPython.display import HTML, display
def progress_bar(value):
    return HTML("""
        <progress
            value='{value}'
            max='100', style='width: 100%'
        >
            {value}
        </progress>
    """.format(value=value*100))
request = drive_service.files().get_media(fileId=fid)
downloaded = io.BytesIO()
downloader = MediaIoBaseDownload(downloaded, request)
done = False
progress_bar_html = display(progress_bar(0), display_id=True)
while not done:
  
  progress, done = downloader.next_chunk()
  progress_bar_html.update(progress_bar(progress.progress()))

print("Done.")
downloaded.seek(0)

# A dict with keys {"lrelu_x", "lrelu_y", "logits_real", "logits_fake", "d_loss_true", "g_loss_true"}
# Only used for testing your loss/activation functions, not for training your GAN
answers = np.load(downloaded)

(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()
train_images = np.reshape(train_images, [train_images.shape[0], -1])
show_images(train_images[:16])
train_images = train_images / 255.0

mnist = tf.data.Dataset.from_tensor_slices(train_images)

def sample_noise(batch_size: int, dim: int) -> tf.Tensor:
    """Generate random uniform noise from -1 to 1.
    
    Inputs:
    - batch_size: integer giving the batch size of noise to generate
    - dim: integer giving the dimension of the the noise to generate
    
    Returns:
    TensorFlow Tensor containing uniform noise in [-1, 1] with shape [batch_size, dim]
    """
    # TODO: sample and return noise
    # Hint: Look for a uniform distribution in the tf.random documentation
    tensor = tf.random.uniform(shape=[batch_size, dim], minval=-1, maxval=1)
    return tensor

def test_sample_noise():
    batch_size = 3
    dim = 4
    z = sample_noise(batch_size, dim)
    # Check z has the correct shape
    assert z.get_shape().as_list() == [batch_size, dim]

    # Make sure z is a Tensor and not a numpy array
    assert isinstance(z, tf.Tensor)

    # Check that we get different noise for different evaluations
    z1 = sample_noise(batch_size, dim)
    z2 = sample_noise(batch_size, dim)
    assert not np.array_equal(z1, z2)

    # Check that we get the correct range
    assert np.all(z1 >= -1.0) and np.all(z1 <= 1.0)

    print("All tests passed!")
    
test_sample_noise()

class Discriminator(tf.keras.Model):
  
  """Model class for the discriminator"""
  def __init__(self,):
    super(Discriminator, self).__init__()
    
    # TODO: create the layers as described above
    self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.01)
    self.layer1 = tf.keras.layers.Dense(256, activation=self.leaky_relu)
    self.layer2 = tf.keras.layers.Dense(256, activation=self.leaky_relu)
    self.layer3 = tf.keras.layers.Dense(1)
   
  @tf.function
  def call(self, x: tf.Tensor) -> tf.Tensor:
    """Compute discriminator score for a batch of input images.
    
    Inputs:
    - x: TensorFlow Tensor of flattened input images, shape [batch_size, 784]
    
    Returns:
    TensorFlow Tensor with shape [batch_size, 1], containing the score 
    for an image being real for each input image.
    """
    
    # TODO: implement the architecture by connecting the layers
    return self.layer3(self.layer2(self.layer1(x)))
    
  @tf.function
  def loss_function(self, predictions, labels):
    return discriminator_loss(predictions, labels)

def test_discriminator(true_count=267009):
    Disc = Discriminator()
    input_size = (None, 784)
    Disc.build(input_size)
    cur_count = sum([np.prod(x.shape) for x in Disc.trainable_variables])
    if cur_count != true_count:
        print('Incorrect number of parameters in discriminator. {0} instead of {1}. Check your achitecture.'.format(cur_count, true_count))
    else:
        print('Correct number of parameters in discriminator.')
        
test_discriminator()

class Generator(tf.keras.Model):
  
  """Model class for the generator"""
  def __init__(self):
    super(Generator, self).__init__()
    
    # TODO: create the layers as described above
    self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.01)
    self.layer1 = tf.keras.layers.Dense(1024, activation=self.leaky_relu)
    self.layer2 = tf.keras.layers.Dense(1024, activation=self.leaky_relu)
    self.layer3 = tf.keras.layers.Dense(784, activation='tanh')
   
  @tf.function
  def call(self, x: tf.Tensor) -> tf.Tensor:
    """Generates a batch of images given a tensor of noise vectors.
    
    Inputs:
    - x: A [batch_size, noise_dim] tensor of noise vectors
    
    Returns:
    TensorFlow Tensor with shape [batch_size, 768], containing the generated images.
    """
    
    # TODO: implement the architecture by connecting the layers
    return self.layer3(self.layer2(self.layer1(x)))
    
  @tf.function
  def loss_function(self, predictions, labels):
    return generator_loss(predictions, labels)

def test_generator(true_count=1952528):
    Gen = Generator()
    input_size = (None, 96)
    Gen.build(input_size)
    cur_count = sum([np.prod(x.shape) for x in Gen.trainable_variables])
    if cur_count != true_count:
        print('Incorrect number of parameters in generator. {0} instead of {1}. Check your achitecture.'.format(cur_count, true_count))
    else:
        print('Correct number of parameters in generator.')
        
test_generator()

"""Compute the GAN loss.
    
    Inputs:
    - logits_real: Tensor, shape [batch_size, 1], output of discriminator for each real image
    - logits_fake: Tensor, shape[batch_size, 1], output of discriminator for each fake image
"""

def discriminator_loss(logits_fake: tf.Tensor, logits_real: tf.Tensor) -> tf.Tensor:
  D_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(logits_fake), logits=logits_fake))
  D_loss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(logits_real), logits=logits_real))
  return D_loss

# TODO: Fill in G_loss
# Remember that the generator is trying to maximize the probability of the discriminator making the incorrect choice
def generator_loss(logits_fake: tf.Tensor, logits_real: tf.Tensor) -> tf.Tensor:
  G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels= tf.ones_like(logits_fake), logits=logits_fake))
  return G_loss

def test_gan_loss(logits_real, logits_fake, d_loss_true, g_loss_true):
  discriminator_model = Discriminator()
  input_size = (None, 784)
  discriminator_model.build(input_size)
  generator_model = Generator()
  input_size = (None, 96)
  generator_model.build(input_size)
  d_loss = discriminator_model.loss_function(logits_fake, logits_real)
  g_loss = generator_model.loss_function(logits_fake, logits_real)
  
  print("Maximum error in d_loss: %g" % rel_error(d_loss_true, d_loss))
  print("Maximum error in g_loss: %g" % rel_error(g_loss_true, g_loss))

test_gan_loss(answers['logits_real'], answers['logits_fake'], answers['d_loss_true'], answers['g_loss_true'])

learning_rate=1e-3
beta_1=0.5

# TODO: make an Adam Optimizer with a learning rate of 1e-3 and a beta_1 of 0.5
# to start (you will have to play with these values)
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5)


def optimize(tape: tf.GradientTape, model: tf.keras.Model, loss: tf.Tensor) -> None:
  """ This optimizes a model with respect to its loss
  
  Inputs:
  - tape: the Gradient Tape
  - model: the model to be trained
  - loss: the model's loss
  """
  # TODO: calculate the gradients our input model and apply them
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

# number of images for each batch
batch_size = 128
# our noise dimension
noise_dim = 96

# create generator and discriminator
generator_model = Generator()
generator_model.build((None, noise_dim))
discriminator_model = Discriminator()
discriminator_model.build((None, 784))

def train(x):
  # random noise fed into our generator
  z = sample_noise(batch_size, noise_dim)

  with tf.GradientTape(persistent=True) as tape:
    # generated images
    G_sample = generator_model(z)

    # scale images to be -1 to 1
    logits_real = discriminator_model(preprocess_img(x))
    # re-use discriminator weights on new inputs
    logits_fake = discriminator_model(G_sample)

    g_loss = generator_model.loss_function(logits_fake, logits_real)
    d_loss = discriminator_model.loss_function(logits_fake, logits_real)
    
  # call optimize on the generator and the discriminator
  optimize(tape, generator_model, g_loss)
  optimize(tape, discriminator_model, d_loss)
  
  return g_loss, d_loss

# a giant helper function
def run_a_gan(show_every=250, print_every=50, batch_size=128, num_epoch=10):
    """Train a GAN for a certain number of epochs.
    
    Inputs:
    - sess: A tf.Session that we want to use to run our data
    - G_train_step: A training step for the Generator
    - G_loss: Generator loss
    - D_train_step: A training step for the Generator
    - D_loss: Discriminator loss
    - G_extra_step: A collection of tf.GraphKeys.UPDATE_OPS for generator
    - D_extra_step: A collection of tf.GraphKeys.UPDATE_OPS for discriminator
    Returns:
        Nothing
    """
    it = 0
    mnist1 = mnist.repeat(num_epoch).shuffle(batch_size).batch(batch_size)
    for minibatch in mnist1:
      # every show often, show a sample result
      if it % show_every == 0:
          samples = generator_model(sample_noise(batch_size, noise_dim))
          fig = show_images(samples[:16])
          plt.show()
          print()
      # run a batch of data through the network
      G_loss_curr,D_loss_curr = train(minibatch)

      # print loss every so often.
      # We want to make sure D_loss doesn't go to 0
      if it % print_every == 0:
          print('Iter: {}, D: {:.4}, G:{:.4}'.format(it, D_loss_curr, G_loss_curr))
      it += 1

run_a_gan()